{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {{cookiecutter.project_name}}\n",
    "\n",
    "{{cookiecutter.description}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from iq_tool_box.datasets import DSModifier, DSWrapper,DSModifier_jpg\n",
    "from iq_tool_box.experiments import ExperimentInfo, ExperimentSetup\n",
    "from iq_tool_box.experiments.experiment_visual import ExperimentVisual\n",
    "from iq_tool_box.experiments.task_execution import PythonScriptTaskExecution\n",
    "from iq_tool_box.metrics import SNRMetric, RERMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from custom_iqf import ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define name of IQF experiment\n",
    "experiment_name = \"???\"\n",
    "\n",
    "#Define path of the original(reference) dataset\n",
    "data_path = \"???\"\n",
    "\n",
    "#DS wrapper is the class that encapsulate a dataset\n",
    "ds_wrapper = DSWrapper(data_path=data_path)\n",
    "\n",
    "#Define path of the training script\n",
    "python_ml_script_path = 'custom_train.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of modifications that will be applied to the original dataset:\n",
    "\n",
    "ds_modifiers_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task execution executes the training loop\n",
    "# In this case the training loop is an empty script,\n",
    "# this is because we evaluate the performance directly on the result of the modifiers.\n",
    "task = PythonScriptTaskExecution( model_script_path = python_ml_script_path )\n",
    "\n",
    "#Experiment definition, pass as arguments all the components defined beforehand\n",
    "experiment = ExperimentSetup(\n",
    "    experiment_name=experiment_name,\n",
    "    task_instance=task,\n",
    "    ref_dsw_train=ds_wrapper,\n",
    "    ds_modifiers_list=ds_modifiers_list,\n",
    "    repetitions=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "The number of runs are all the combinations between repetitions, modifiers list as well as extra_train_params variations.\n",
    "\n",
    "(you can skip this step in demo pre-executed datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "ExperimentInfo is used to retrieve all the information of the whole experiment. \n",
    "It contains built in operations but also it can be used to retrieve raw data for futher analysis. Its instance can also be used to apply metrics per run. Some custum metrics are presented. They where build by inheriting **Metric** from **iq_tool_box.metrics**.\n",
    "\n",
    "(you can skip this step in demo pre-executed datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExperimentInfo is used to retrieve all the information of the whole experiment. \n",
    "# It contains built in operations but also it can be used to retrieve raw data for futher analysis\n",
    "\n",
    "experiment_info = ExperimentInfo(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Calculating CusotmMetric metrics...')\n",
    "\n",
    "_ = experiment_info.apply_metric_per_run(\n",
    "#     CustomMetric( ),\n",
    "    ds_wrapper.json_annotations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = experiment_info.get_df(\n",
    "    ds_params=[\"modifier\"],\n",
    "    metrics=['???','???'],\n",
    "    dropna=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ev = ExperimentVisual(df, None)\n",
    "\n",
    "# ev.visualize(\n",
    "#     plot_kind=\"bars\",\n",
    "#     xvar=\"ds_modifier\",\n",
    "#     yvar=\"ssim\",\n",
    "#     legend_var='psnr',\n",
    "#     title=\"\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
